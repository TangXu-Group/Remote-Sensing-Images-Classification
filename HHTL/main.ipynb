{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/admin1/lmt/pytorch_project/transformer_ViT\n",
      "checkpoint  image  loss        main.py\tmodels\t   run.ipynb\n",
      "dataset     log    main.ipynb  main.sh\tparameter  utils\n",
      "\n",
      "test_Data 5000\n",
      "\n",
      "num_class: 30\n",
      "03/09/2022 11:45:50 - INFO - __main__ - classifier: token\n",
      "hidden_size: 768\n",
      "patches:\n",
      "  size: !!python/tuple\n",
      "  - 32\n",
      "  - 32\n",
      "representation_size: null\n",
      "transformer:\n",
      "  attention_dropout_rate: 0.0\n",
      "  dropout_rate: 0.1\n",
      "  mlp_dim: 3072\n",
      "  num_heads: 12\n",
      "  num_layers: 12\n",
      "\n",
      "03/09/2022 11:45:50 - INFO - __main__ - Training parameters Namespace(data_dir='/home/admin1/lmt/pytorch_project/transformer_ViT/dataset', dataset='AID55', dataset_slic='AID55_slic', decay_type='cosine', epoch=300, eval_batch_size=64, img_size=384, img_slic_te='/home/admin1/lmt/pytorch_project/transformer_ViT/dataset/AID55_slic/test.txt', img_slic_tr='/home/admin1/lmt/pytorch_project/transformer_ViT/dataset/AID55_slic/train.txt', img_te='/home/admin1/lmt/pytorch_project/transformer_ViT/dataset/AID55/test.txt', img_tr='/home/admin1/lmt/pytorch_project/transformer_ViT/dataset/AID55/train.txt', label_dim=30, learning_rate=0.03, log_dir='/home/admin1/lmt/pytorch_project/transformer_ViT/log', model_type='ViT-B_32', name='AID55_best', num_steps=20000, parameters='parameter', pretrained_dir='checkpoint/ViT-B_32.npz', seed=42, show_log=-1, train_batch_size=32, warmup_steps=500, weight_decay=0)\n",
      "03/09/2022 11:45:50 - INFO - __main__ - Total Parameter: \t175.1M\n",
      "0/300:   0%|                                            | 0/157 [00:00<?, ?it/s]/home/admin1/anaconda3/envs/lmt/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
      "0/300: 100%|█| 157/157 [02:08<00:00,  1.22it/s, ta:0.7500,loss:0.5708,lr:0.00942\n",
      "Epoch: 0   test_acc: 0.8978 loss: 0.5707727670669556\n",
      "1/300: 100%|█| 157/157 [02:08<00:00,  1.22it/s, ta:1.0000,loss:0.0342,lr:0.01884\n",
      "Epoch: 1   test_acc: 0.9284 loss: 0.03424377366900444\n",
      "2/300: 100%|█| 157/157 [02:08<00:00,  1.22it/s, ta:0.8750,loss:0.1812,lr:0.02826\n",
      "Epoch: 2   test_acc: 0.9204 loss: 0.18116514384746552\n",
      "3/300: 100%|█| 157/157 [02:12<00:00,  1.19it/s, ta:0.8750,loss:0.2849,lr:0.02999\n",
      "Epoch: 3   test_acc: 0.882 loss: 0.28489354252815247\n",
      "4/300: 100%|█| 157/157 [02:11<00:00,  1.19it/s, ta:0.8750,loss:0.1752,lr:0.02998\n",
      "Epoch: 4   test_acc: 0.912 loss: 0.1752013862133026\n",
      "5/300: 100%|█| 157/157 [02:13<00:00,  1.17it/s, ta:1.0000,loss:0.0207,lr:0.02996\n",
      "Epoch: 5   test_acc: 0.9 loss: 0.020725252106785774\n",
      "6/300: 100%|█| 157/157 [02:16<00:00,  1.15it/s, ta:1.0000,loss:0.0203,lr:0.02993\n",
      "Epoch: 6   test_acc: 0.9054 loss: 0.020338794216513634\n",
      "7/300: 100%|█| 157/157 [02:09<00:00,  1.21it/s, ta:1.0000,loss:0.0026,lr:0.02988\n",
      "Epoch: 7   test_acc: 0.9434 loss: 0.002635606098920107\n",
      "8/300: 100%|█| 157/157 [02:09<00:00,  1.21it/s, ta:1.0000,loss:0.0065,lr:0.02983\n",
      "Epoch: 8   test_acc: 0.949 loss: 0.0064664180390536785\n",
      "9/300: 100%|█| 157/157 [02:14<00:00,  1.17it/s, ta:1.0000,loss:0.0030,lr:0.02977\n",
      "Epoch: 9   test_acc: 0.9396 loss: 0.0029603387229144573\n",
      "10/300: 100%|█| 157/157 [02:18<00:00,  1.14it/s, ta:1.0000,loss:0.0001,lr:0.0297\n",
      "Epoch: 10   test_acc: 0.9516 loss: 0.00011899515811819583\n",
      "11/300: 100%|█| 157/157 [02:12<00:00,  1.18it/s, ta:1.0000,loss:0.0021,lr:0.0296\n",
      "Epoch: 11   test_acc: 0.949 loss: 0.0021329571027308702\n",
      "12/300: 100%|█| 157/157 [02:13<00:00,  1.18it/s, ta:1.0000,loss:0.0037,lr:0.0295\n",
      "Epoch: 12   test_acc: 0.9574 loss: 0.0036619454622268677\n",
      "13/300: 100%|█| 157/157 [02:09<00:00,  1.21it/s, ta:1.0000,loss:0.0001,lr:0.0294\n",
      "Epoch: 13   test_acc: 0.9614 loss: 7.895182352513075e-05\n",
      "14/300: 100%|█| 157/157 [02:10<00:00,  1.20it/s, ta:1.0000,loss:0.0023,lr:0.0293\n",
      "Epoch: 14   test_acc: 0.9652 loss: 0.0023192756343632936\n",
      "15/300: 100%|█| 157/157 [02:13<00:00,  1.18it/s, ta:1.0000,loss:0.0000,lr:0.0292\n",
      "Epoch: 15   test_acc: 0.964 loss: 2.8236881917109713e-05\n",
      "16/300: 100%|█| 157/157 [02:15<00:00,  1.16it/s, ta:1.0000,loss:0.0001,lr:0.0290\n",
      "Epoch: 16   test_acc: 0.9656 loss: 8.62331289681606e-05\n",
      "17/300: 100%|█| 157/157 [02:15<00:00,  1.16it/s, ta:1.0000,loss:0.0003,lr:0.0289\n",
      "Epoch: 17   test_acc: 0.9646 loss: 0.00028536832542158663\n",
      "18/300: 100%|█| 157/157 [02:13<00:00,  1.17it/s, ta:1.0000,loss:0.0016,lr:0.0288\n",
      "Epoch: 18   test_acc: 0.9644 loss: 0.0016315083485096693\n",
      "19/300: 100%|█| 157/157 [02:09<00:00,  1.21it/s, ta:1.0000,loss:0.0001,lr:0.0286\n",
      "Epoch: 19   test_acc: 0.964 loss: 6.270164885791019e-05\n",
      "20/300: 100%|█| 157/157 [02:09<00:00,  1.21it/s, ta:1.0000,loss:0.0037,lr:0.0285\n",
      "Epoch: 20   test_acc: 0.9642 loss: 0.003673961153253913\n",
      "21/300: 100%|█| 157/157 [02:12<00:00,  1.19it/s, ta:1.0000,loss:0.0044,lr:0.0283\n",
      "Epoch: 21   test_acc: 0.9656 loss: 0.004415253642946482\n",
      "22/300: 100%|█| 157/157 [02:16<00:00,  1.15it/s, ta:1.0000,loss:0.0014,lr:0.0281\n",
      "Epoch: 22   test_acc: 0.9642 loss: 0.001369976787827909\n",
      "23/300: 100%|█| 157/157 [02:16<00:00,  1.15it/s, ta:1.0000,loss:0.0001,lr:0.0279\n",
      "Epoch: 23   test_acc: 0.9646 loss: 8.451387111563236e-05\n",
      "24/300: 100%|█| 157/157 [02:11<00:00,  1.19it/s, ta:1.0000,loss:0.0055,lr:0.0277\n",
      "Epoch: 24   test_acc: 0.9646 loss: 0.005460329819470644\n",
      "25/300: 100%|█| 157/157 [02:09<00:00,  1.21it/s, ta:1.0000,loss:0.0003,lr:0.0275\n",
      "Epoch: 25   test_acc: 0.9654 loss: 0.00025483177159912884\n",
      "26/300: 100%|█| 157/157 [02:10<00:00,  1.20it/s, ta:1.0000,loss:0.0025,lr:0.0273\n",
      "Epoch: 26   test_acc: 0.9654 loss: 0.002453007036820054\n",
      "27/300: 100%|█| 157/157 [02:14<00:00,  1.17it/s, ta:1.0000,loss:0.0009,lr:0.0271\n",
      "Epoch: 27   test_acc: 0.9638 loss: 0.0008991158683784306\n",
      "28/300: 100%|█| 157/157 [02:16<00:00,  1.15it/s, ta:1.0000,loss:0.0018,lr:0.0269\n",
      "Epoch: 28   test_acc: 0.965 loss: 0.001808414701372385\n",
      "29/300: 100%|█| 157/157 [02:17<00:00,  1.14it/s, ta:1.0000,loss:0.0023,lr:0.0266\n",
      "Epoch: 29   test_acc: 0.9642 loss: 0.0022617834620177746\n",
      "30/300: 100%|█| 157/157 [02:15<00:00,  1.16it/s, ta:1.0000,loss:0.0026,lr:0.0264\n",
      "Epoch: 30   test_acc: 0.9648 loss: 0.002644868800416589\n",
      "31/300: 100%|█| 157/157 [02:12<00:00,  1.18it/s, ta:1.0000,loss:0.0001,lr:0.0261\n",
      "Epoch: 31   test_acc: 0.9624 loss: 5.436291758087464e-05\n",
      "32/300: 100%|█| 157/157 [02:10<00:00,  1.20it/s, ta:1.0000,loss:0.0015,lr:0.0259\n",
      "Epoch: 32   test_acc: 0.9634 loss: 0.0014594786334782839\n",
      "33/300: 100%|█| 157/157 [02:13<00:00,  1.17it/s, ta:1.0000,loss:0.0022,lr:0.0256\n",
      "Epoch: 33   test_acc: 0.9632 loss: 0.0022046200465410948\n",
      "34/300: 100%|█| 157/157 [02:16<00:00,  1.15it/s, ta:1.0000,loss:0.0013,lr:0.0254\n",
      "Epoch: 34   test_acc: 0.964 loss: 0.0012681022053584456\n",
      "35/300: 100%|█| 157/157 [02:18<00:00,  1.13it/s, ta:1.0000,loss:0.0012,lr:0.0251\n",
      "Epoch: 35   test_acc: 0.9636 loss: 0.0011500244727358222\n",
      "36/300: 100%|█| 157/157 [02:18<00:00,  1.13it/s, ta:1.0000,loss:0.0001,lr:0.0248\n",
      "Epoch: 36   test_acc: 0.9646 loss: 0.0001466101675760001\n",
      "37/300: 100%|█| 157/157 [02:15<00:00,  1.16it/s, ta:1.0000,loss:0.0037,lr:0.0245\n",
      "Epoch: 37   test_acc: 0.9644 loss: 0.0036559219006448984\n",
      "38/300: 100%|█| 157/157 [02:11<00:00,  1.20it/s, ta:1.0000,loss:0.0015,lr:0.0242\n",
      "Epoch: 38   test_acc: 0.9648 loss: 0.0014537475071847439\n",
      "39/300: 100%|█| 157/157 [02:13<00:00,  1.18it/s, ta:1.0000,loss:0.0015,lr:0.0239\n",
      "Epoch: 39   test_acc: 0.9648 loss: 0.0014661347959190607\n",
      "40/300: 100%|█| 157/157 [02:17<00:00,  1.14it/s, ta:1.0000,loss:0.0000,lr:0.0236\n",
      "Epoch: 40   test_acc: 0.9646 loss: 4.327029819251038e-05\n",
      "41/300: 100%|█| 157/157 [02:24<00:00,  1.09it/s, ta:1.0000,loss:0.0008,lr:0.0233\n",
      "Epoch: 41   test_acc: 0.9646 loss: 0.0007624555728398263\n",
      "42/300: 100%|█| 157/157 [02:26<00:00,  1.07it/s, ta:1.0000,loss:0.0000,lr:0.0230\n",
      "Epoch: 42   test_acc: 0.9654 loss: 3.175325400661677e-05\n",
      "43/300: 100%|█| 157/157 [02:25<00:00,  1.08it/s, ta:1.0000,loss:0.0009,lr:0.0226\n",
      "Epoch: 43   test_acc: 0.9652 loss: 0.0009387290338054299\n",
      "44/300: 100%|█| 157/157 [02:17<00:00,  1.15it/s, ta:1.0000,loss:0.0025,lr:0.0223\n",
      "Epoch: 44   test_acc: 0.9654 loss: 0.0024687903933227062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/300: 100%|█| 157/157 [02:15<00:00,  1.16it/s, ta:1.0000,loss:0.0002,lr:0.0220\n",
      "Epoch: 45   test_acc: 0.965 loss: 0.0002053640055237338\n",
      "46/300: 100%|█| 157/157 [02:17<00:00,  1.14it/s, ta:1.0000,loss:0.0008,lr:0.0216\n",
      "Epoch: 46   test_acc: 0.9652 loss: 0.0008139325655065477\n",
      "47/300: 100%|█| 157/157 [02:25<00:00,  1.08it/s, ta:1.0000,loss:0.0001,lr:0.0213\n",
      "Epoch: 47   test_acc: 0.9652 loss: 0.00011269986134720966\n",
      "48/300: 100%|█| 157/157 [02:29<00:00,  1.05it/s, ta:1.0000,loss:0.0000,lr:0.0210\n",
      "Epoch: 48   test_acc: 0.9656 loss: 1.4185297004587483e-05\n",
      "49/300: 100%|█| 157/157 [02:25<00:00,  1.08it/s, ta:1.0000,loss:0.0017,lr:0.0206\n",
      "Epoch: 49   test_acc: 0.9654 loss: 0.0016546332044526935\n",
      "50/300: 100%|█| 157/157 [02:21<00:00,  1.11it/s, ta:1.0000,loss:0.0004,lr:0.0203\n",
      "Epoch: 50   test_acc: 0.9654 loss: 0.0003532467526383698\n",
      "51/300: 100%|█| 157/157 [02:13<00:00,  1.17it/s, ta:1.0000,loss:0.0002,lr:0.0199\n",
      "Epoch: 51   test_acc: 0.9656 loss: 0.00019423245976213366\n",
      "52/300: 100%|█| 157/157 [02:13<00:00,  1.18it/s, ta:1.0000,loss:0.0001,lr:0.0195\n",
      "Epoch: 52   test_acc: 0.9658 loss: 0.00012352829799056053\n",
      "53/300: 100%|█| 157/157 [02:18<00:00,  1.13it/s, ta:1.0000,loss:0.0001,lr:0.0192\n",
      "Epoch: 53   test_acc: 0.9656 loss: 9.622224752092734e-05\n",
      "54/300: 100%|█| 157/157 [02:28<00:00,  1.06it/s, ta:1.0000,loss:0.0012,lr:0.0188\n",
      "Epoch: 54   test_acc: 0.9658 loss: 0.0011619080323725939\n",
      "55/300: 100%|█| 157/157 [02:28<00:00,  1.06it/s, ta:1.0000,loss:0.0001,lr:0.0184\n",
      "Epoch: 55   test_acc: 0.9656 loss: 6.224826211109757e-05\n",
      "56/300: 100%|█| 157/157 [02:24<00:00,  1.08it/s, ta:1.0000,loss:0.0014,lr:0.0181\n",
      "Epoch: 56   test_acc: 0.9656 loss: 0.0014256276190280914\n",
      "57/300: 100%|█| 157/157 [02:17<00:00,  1.14it/s, ta:1.0000,loss:0.0028,lr:0.0177\n",
      "Epoch: 57   test_acc: 0.9656 loss: 0.002758436370640993\n",
      "58/300: 100%|█| 157/157 [02:14<00:00,  1.17it/s, ta:1.0000,loss:0.0015,lr:0.0173\n",
      "Epoch: 58   test_acc: 0.966 loss: 0.0014917172957211733\n",
      "59/300: 100%|█| 157/157 [02:13<00:00,  1.17it/s, ta:1.0000,loss:0.0015,lr:0.0170\n",
      "Epoch: 59   test_acc: 0.9656 loss: 0.0015021809376776218\n",
      "60/300: 100%|█| 157/157 [02:22<00:00,  1.10it/s, ta:1.0000,loss:0.0034,lr:0.0166\n",
      "Epoch: 60   test_acc: 0.9656 loss: 0.003394713392481208\n",
      "61/300: 100%|█| 157/157 [02:27<00:00,  1.06it/s, ta:1.0000,loss:0.0013,lr:0.0162\n",
      "Epoch: 61   test_acc: 0.9654 loss: 0.0012843505246564746\n",
      "62/300: 100%|█| 157/157 [02:28<00:00,  1.06it/s, ta:1.0000,loss:0.0048,lr:0.0158\n",
      "Epoch: 62   test_acc: 0.9658 loss: 0.004801824223250151\n",
      "63/300: 100%|█| 157/157 [02:22<00:00,  1.10it/s, ta:1.0000,loss:0.0016,lr:0.0154\n",
      "Epoch: 63   test_acc: 0.9654 loss: 0.0015817449893802404\n",
      "64/300: 100%|█| 157/157 [02:17<00:00,  1.14it/s, ta:1.0000,loss:0.0019,lr:0.0151\n",
      "Epoch: 64   test_acc: 0.9654 loss: 0.0019320612773299217\n",
      "65/300: 100%|█| 157/157 [02:15<00:00,  1.16it/s, ta:1.0000,loss:0.0012,lr:0.0147\n",
      "Epoch: 65   test_acc: 0.9658 loss: 0.0012152056442573667\n",
      "66/300: 100%|█| 157/157 [02:18<00:00,  1.14it/s, ta:1.0000,loss:0.0012,lr:0.0143\n",
      "Epoch: 66   test_acc: 0.9658 loss: 0.001176146324723959\n",
      "67/300: 100%|█| 157/157 [02:25<00:00,  1.08it/s, ta:1.0000,loss:0.0014,lr:0.0139\n",
      "Epoch: 67   test_acc: 0.9658 loss: 0.0014230158412829041\n",
      "68/300:  38%|▍| 60/157 [00:59<01:46,  1.10s/it, ta:1.0000,loss:0.0017,lr:0.01382"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "!ls\n",
    "# !python main.py\n",
    "# !chmod u+x *.sh\n",
    "!./main.sh\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:lmt]",
   "language": "python",
   "name": "conda-env-lmt-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
